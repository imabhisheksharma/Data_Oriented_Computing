{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Text classification with Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Abhishek Kumar Sharma\n",
    "## Student Id: 5037 2679\n",
    "## Class: MTH 548\n",
    "## Date: March 14, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you will be working with 3 datasets:\n",
    "$$(1) \\text{1 or more presidential debate transcripts that you scraped last week.}$$\n",
    "\n",
    "$$(2) \\text{movie_reviews.zip}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file movie_reviews.zip is a zipped csv file containing texts of about 25,000 movie reviews. Each review is accompanied by a label, indicating if the review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by implementing model for movie reviews using Naive Bayes. The idea is to create a training data set and we will create a dataframe with two columns “positive” and “negative”. Rows of the dataframe labeled by words appearing in the text of the reviews. The entries of a row will show how many times the given word appears in the text of negative reviews and how many times it appears in positive reviews.\n",
    "\n",
    "We will do this by preprocessing the data, which includes cleaning of data, tokenization and removing of stopwords and then creating the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                        # To work with dataframes\n",
    "import matplotlib.pyplot as plt                            # To plot graphs if required\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split       # To create the training and test dataset\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np                                          \n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score                  # To check the accuracy score of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This film is absolutely awful, but nevertheles...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well since seeing part's 1 through 3 I can hon...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got to see this film at a preview and was da...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  This film is absolutely awful, but nevertheles...  negative\n",
       "1  Well since seeing part's 1 through 3 I can hon...  negative\n",
       "2  I got to see this film at a preview and was da...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\"movie_reviews.zip\")   # creating the dataframe for movie reviews\n",
    "movies[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains uppercase and lowercase letters. So we convert the reviews in the lowercase so that it is easy for us to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"review\"] = movies[\"review\"].str.lower()   # Converting every review into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this film is absolutely awful, but nevertheles...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well since seeing part's 1 through 3 i can hon...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i got to see this film at a preview and was da...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this adaptation positively butchers a classic ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>råzone is an awful movie! it is so simple. it ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>with this movie being the only dirty harry mov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>any screen adaptation of a john grisham story ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>this film captured my heart from the very begi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>a deplorable social condition triggers off the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>always enjoy the great acting of drew barrymor...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      this film is absolutely awful, but nevertheles...  negative\n",
       "1      well since seeing part's 1 through 3 i can hon...  negative\n",
       "2      i got to see this film at a preview and was da...  positive\n",
       "3      this adaptation positively butchers a classic ...  negative\n",
       "4      råzone is an awful movie! it is so simple. it ...  negative\n",
       "...                                                  ...       ...\n",
       "24995  with this movie being the only dirty harry mov...  positive\n",
       "24996  any screen adaptation of a john grisham story ...  positive\n",
       "24997  this film captured my heart from the very begi...  positive\n",
       "24998  a deplorable social condition triggers off the...  positive\n",
       "24999  always enjoy the great acting of drew barrymor...  positive\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function do the cleaning of each review. That is, the function will eliminate the html codes, symbols etc which are not relevent for the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(string):\n",
    "    text = BeautifulSoup(string).get_text()\n",
    "    clean_text = re.sub(\"[^a-z\\s]+\", \" \", text)  \n",
    "    clean_text = re.sub(\"(\\s+)\", \" \", clean_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also remove the stop words because these words does not depect any positive or negative sentiment and hence unnecessary for our cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your\n"
     ]
    }
   ],
   "source": [
    "with open(\"stopwords.txt\") as f:   # Downloading the stopwords file\n",
    "    stops = f.read()\n",
    "\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(string):\n",
    "    l = [w for w in re.split(\"\\W+\", string) if not w in stops]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start the processing of our training data into the dataframe. We start by creating a bag of words which contains the words from the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_pos = Counter([])\n",
    "counter_neg = Counter([])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(movies['review'], \n",
    "                                                    movies['sentiment'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "n = len(X_train)\n",
    "for i in range(len(X_train)):\n",
    "    words = movies.loc[i,'review']\n",
    "    words = cleaning_data(words)    \n",
    "    words = tokenize_text(words)\n",
    "    \n",
    "    if movies.loc[i,'sentiment'] == \"positive\":\n",
    "        counter_pos += Counter(words)\n",
    "    else:\n",
    "        counter_neg += Counter(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Negative\":counter_neg,\"Positive\":counter_pos}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will count the number of times a word appear in positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>15394</td>\n",
       "      <td>16576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>685</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>1226</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nevertheless</th>\n",
       "      <td>58</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hilarious</th>\n",
       "      <td>306</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landscaped</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lachlin</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bruiser</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disbelievable</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flipside</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67643 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Negative  Positive\n",
       "film              15394     16576\n",
       "absolutely          685       512\n",
       "awful              1226       129\n",
       "nevertheless         58       122\n",
       "hilarious           306       476\n",
       "...                 ...       ...\n",
       "landscaped            0         1\n",
       "lachlin               0         1\n",
       "bruiser               0         1\n",
       "disbelievable         0         1\n",
       "flipside              0         1\n",
       "\n",
       "[67643 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = pd.DataFrame(d)\n",
    "wc = wc.fillna(0)\n",
    "wc.Negative = wc.Negative.astype(int)\n",
    "wc.Positive = wc.Positive.astype(int)\n",
    "wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the dataframe wc is our required dataframe.\n",
    "\n",
    "Now as we have successfully constructed the required dataframe, we will implement the Naive Bayes model on the movie review dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_probs(review_text, alpha = 1.0):\n",
    "\n",
    "    tot = np.array(wc.sum()).sum()\n",
    "    prod = np.ones(2)\n",
    "    prod[0] = wc['Negative'].sum()/(tot)\n",
    "    prod[1] = wc['Positive'].sum()/(tot)\n",
    "    prod = np.log(prod)\n",
    "\n",
    "    words = cleaning_data(review_text).lower()\n",
    "    words = tokenize_text(words)\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in stops and word in list(wc.index):\n",
    "            w = wc.loc[word]        \n",
    "            p = (w+alpha)/(np.array(wc.sum())+ 2*alpha) # The probability P[x|y] with laplace smoothing       \n",
    "            prod += np.log(np.array(p))\n",
    "            \n",
    "    return prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we conside the following review and check if our model successfully able to figure out if the review is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"I saw this recent Woody Allen film because I\\'m a fan of\n",
    "his work and I make it a point to try to see everything he does, though\n",
    "the reviews of this film led me to expect a disappointing effort. They were right.\n",
    "This is a confused movie that can\\'t decide whether it wants to be a comedy,\n",
    "a romantic fantasy, or a drama about female mid-life crisis. It fails at all three.\n",
    "<br /><br />Alice (Mia Farrow) is a restless middle aged woman who has married into\n",
    "great wealth and leads a life of aimless luxury with her rather boring husband and\n",
    "their two small children. This rather mundane plot concept is livened up with such\n",
    "implausibilities as an old Chinese folk healer who makes her invisible with some magic\n",
    "herbs, and the ghost of a former lover (with whom she flies over Manhattan). If these\n",
    "additions sound too fantastic for you, how about something more prosaic, like an affair\n",
    "with a saxophone player?<br /><br />I was never quite sure of what this mixed up muddle\n",
    "was trying to say. There are only a handful of truly funny moments in the film,\n",
    "and the endingis a really preposterous touch of Pollyanna.<br /><br />Rent \\'Crimes and\n",
    "Misdemeanors\\' instead, a superbly well-done film that suceeds in combining comedy with\n",
    "a serious consideration of ethics and morals. Or go back to \"Annie Hall\" or \"Manhattan\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-878.29118717, -884.64099757])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_probs(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since prod[0] > prod[1] $\\implies$ the given review is a negative review according to the Naive Bayes model, which is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will implement this model for our test set and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [1:06:20<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "Y_pred = pd.DataFrame(columns = [\"sentiment\"])\n",
    "for review in tqdm(X_test):\n",
    "    prod = rev_probs(review)\n",
    "    if prod[0] >= prod[1]:\n",
    "        Y_pred.loc[len(Y_pred.index)] = [\"negative\"] \n",
    "    else:\n",
    "        Y_pred.loc[len(Y_pred.index)] = [\"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(columns = [\"Y_pred\", \"Y_test\"])\n",
    "prediction[\"Y_pred\"] = Y_pred[\"sentiment\"]\n",
    "prediction[\"Y_test\"] = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_pred</th>\n",
       "      <th>Y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y_pred    Y_test\n",
       "0     negative  negative\n",
       "1     negative  positive\n",
       "2     negative  negative\n",
       "3     positive  positive\n",
       "4     negative  negative\n",
       "...        ...       ...\n",
       "4995  positive  positive\n",
       "4996  positive  positive\n",
       "4997  negative  positive\n",
       "4998  positive  positive\n",
       "4999  negative  negative\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the given model is  90.44 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the given model is \", accuracy_score(prediction[\"Y_pred\"], prediction[\"Y_test\"])*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the accuracy of our model is about 90%, i.e. our model has correctly tell us if the review is positive or negative about 90% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presidential Debate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of studying the presidential debate transcripts is to study how well naive Bayes classifier can predict which person is speaking during a debate. We will implement the model for the Presidential Debate at Case Western Reserve University and Cleveland Clinic in Cleveland, Ohio, which too place on September 29th 2020.\n",
    "\n",
    "We will use the same idea as in the above model. We count the number of times a words appear in the text spoken by Biden, Trump and Wallace. After constructing this dataset, we will implement the Naive Bayes model.\n",
    "\n",
    "We start by scrapping the webpage containing the debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.debates.org/voter-education/debate-transcripts/september-29-2020-debate-transcript/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get(url).text\n",
    "soup = BeautifulSoup(text, \"html.parser\")\n",
    "page = soup.find(id = \"content-sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "debate = page.findAll(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will construct a dataframe which contains the text spoken by Biden, Trump and Wallace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"Text\", \"Speaker\"])\n",
    "for p in debate:\n",
    "    if 'BIDEN:' in p.text:\n",
    "        df.loc[len(df)] = {\"Text\": p.text.strip(\"BIDEN:\"), 'Speaker': \"BIDEN\" }\n",
    "    \n",
    "    elif \"TRUMP:\" in p.text:\n",
    "        df.loc[len(df)] = {\"Text\": p.text.strip(\"TRUMP:\"), 'Speaker': \"TRUMP\" }\n",
    "    \n",
    "    elif \"WALLACE:\" in p.text:\n",
    "        df.loc[len(df)] = {\"Text\": p.text.strip(\"WALLACE:\"), 'Speaker': \"WALLACE\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good evening from the Health Education Campus...</td>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How you doing, man?</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How are you doing?</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m well.</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gentlemen, a lot of people have been waiting ...</td>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Gentlemen, just say that’s the end of it [cro...</td>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>I want to see an honest ballot count.</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>We’re going to leave it there. . .</td>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>And I think he does too. . .</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>… to be continued in more debates as we go on...</td>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Speaker\n",
       "0     Good evening from the Health Education Campus...  WALLACE\n",
       "1                                  How you doing, man?    BIDEN\n",
       "2                                   How are you doing?    TRUMP\n",
       "3                                            I’m well.    BIDEN\n",
       "4     Gentlemen, a lot of people have been waiting ...  WALLACE\n",
       "..                                                 ...      ...\n",
       "851   Gentlemen, just say that’s the end of it [cro...  WALLACE\n",
       "852              I want to see an honest ballot count.    TRUMP\n",
       "853                 We’re going to leave it there. . .  WALLACE\n",
       "854                       And I think he does too. . .    TRUMP\n",
       "855   … to be continued in more debates as we go on...  WALLACE\n",
       "\n",
       "[856 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"] = df[\"Text\"].str.lower() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will construct the dataframe which will be our bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_biden = Counter([])\n",
    "counter_trump = Counter([])\n",
    "counter_wallace = Counter([])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], \n",
    "                                                    df['Speaker'], \n",
    "                                                    train_size = 0.8,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "n = len(X_train)\n",
    "for i in range(len(X_train)):\n",
    "    words = df.loc[i,'Text'].lower()\n",
    "    words = cleaning_data(words)    \n",
    "    words = tokenize_text(words)\n",
    "    \n",
    "    if df.loc[i,'Speaker'] == \"BIDEN\":\n",
    "        counter_biden += Counter(words)\n",
    "    elif df.loc[i, \"Speaker\"] == \"TRUMP\":\n",
    "        counter_trump += Counter(words)\n",
    "    elif df.loc[i, \"Speaker\"] == \"WALLACE\":\n",
    "        counter_wallace += Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Biden\":counter_biden,\"Trump\":counter_trump, \"Wallace\": counter_wallace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = pd.DataFrame(d)\n",
    "wc = wc.fillna(0)\n",
    "wc.Biden = wc.Biden.astype(int)\n",
    "wc.Trump = wc.Trump.astype(int)\n",
    "wc.Wallace = wc.Wallace.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biden</th>\n",
       "      <th>Trump</th>\n",
       "      <th>Wallace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doing</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulled</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolled</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>environmental</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confront</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Biden  Trump  Wallace\n",
       "doing              9     10        1\n",
       "man                7      2        0\n",
       "well              20     20       10\n",
       "first              3      2       17\n",
       "thank              1      2        1\n",
       "...              ...    ...      ...\n",
       "science            0      0        3\n",
       "pulled             0      0        1\n",
       "rolled             0      0        1\n",
       "environmental      0      0        1\n",
       "confront           0      0        1\n",
       "\n",
       "[1531 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Naive Bayes for Presidential Debate 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_probs(review_text, alpha = 1.0):\n",
    "\n",
    "    tot = np.array(wc.sum()).sum()\n",
    "    prod = np.ones(3)\n",
    "    prod[0] = wc['Biden'].sum()/(tot)\n",
    "    prod[1] = wc['Trump'].sum()/(tot)\n",
    "    prod[2] = wc[\"Wallace\"].sum()/(tot)\n",
    "    prod = np.log(prod)\n",
    "\n",
    "    words = cleaning_data(review_text).lower()\n",
    "    words = tokenize_text(words)\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in stops and word in list(wc.index):\n",
    "            w = wc.loc[word]        \n",
    "            p = (w+alpha)/(np.array(wc.sum())+ 2*alpha) # The probability P[x|y] with laplace smoothing       \n",
    "            prod += np.log(np.array(p))\n",
    "            \n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [00:01<00:00, 139.14it/s]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = pd.DataFrame(columns = [\"Speaker\"])\n",
    "for text in tqdm(X_test):\n",
    "    prod = rev_probs(text)\n",
    "    loc = prod.argmax()\n",
    "    if loc == 0:\n",
    "        Y_pred.loc[len(Y_pred.index)] = [\"BIDEN\"] \n",
    "    elif loc == 1:\n",
    "        Y_pred.loc[len(Y_pred.index)] = [\"TRUMP\"]\n",
    "    else:\n",
    "        Y_pred.loc[len(Y_pred.index)] = [\"WALLACE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Speaker\n",
       "0      BIDEN\n",
       "1    WALLACE\n",
       "2    WALLACE\n",
       "3      TRUMP\n",
       "4      BIDEN\n",
       "..       ...\n",
       "167    BIDEN\n",
       "168    TRUMP\n",
       "169  WALLACE\n",
       "170    TRUMP\n",
       "171    TRUMP\n",
       "\n",
       "[172 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(columns = [\"Y_pred\", \"Y_test\"])\n",
    "prediction[\"Y_pred\"] = Y_pred[\"Speaker\"]\n",
    "prediction[\"Y_test\"] = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the given model is  84.88372093023256 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the given model is \", accuracy_score(prediction[\"Y_pred\"], prediction[\"Y_test\"])*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the accuracy of our model is about 85%, i.e. our model has correctly tell us if the review is positive or negative about 85% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what are some examples which our programme has incorrectly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"y_predicted\", \"y_test\"])\n",
    "df[\"y_predicted\"] = Y_pred\n",
    "df[\"y_test\"] = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_predicted</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIDEN</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WALLACE</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WALLACE</td>\n",
       "      <td>WALLACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIDEN</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>BIDEN</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>WALLACE</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_predicted   y_test\n",
       "0         BIDEN    TRUMP\n",
       "1       WALLACE    TRUMP\n",
       "2       WALLACE  WALLACE\n",
       "3         TRUMP    TRUMP\n",
       "4         BIDEN    BIDEN\n",
       "..          ...      ...\n",
       "167       BIDEN    BIDEN\n",
       "168       TRUMP    TRUMP\n",
       "169     WALLACE    TRUMP\n",
       "170       TRUMP    TRUMP\n",
       "171       TRUMP    TRUMP\n",
       "\n",
       "[172 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above that the test set example 0 and 1 are incorrectly identified by our programme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " … most ridiculous. . . where airplanes are out of business. where two car systems are out. . .\n"
     ]
    }
   ],
   "source": [
    "print(list(X_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . . . we could, very quickly\n"
     ]
    }
   ],
   "source": [
    "print(list(X_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check how the difference in training datasize affect the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [00:01<00:00, 97.69it/s]\n",
      "100%|██████████| 172/172 [00:01<00:00, 97.39it/s] \n",
      "100%|██████████| 172/172 [00:01<00:00, 122.42it/s]\n",
      "100%|██████████| 172/172 [00:02<00:00, 74.68it/s]\n",
      "100%|██████████| 172/172 [00:02<00:00, 69.74it/s]\n",
      "100%|██████████| 172/172 [00:02<00:00, 69.15it/s]\n",
      "100%|██████████| 172/172 [00:02<00:00, 64.80it/s]\n",
      "100%|██████████| 172/172 [00:02<00:00, 69.35it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.zeros(9)\n",
    "for i in range(1, 9):\n",
    "    counter_biden = Counter([])\n",
    "    counter_trump = Counter([])\n",
    "    counter_wallace = Counter([])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['Text'], \n",
    "                                                        df['Speaker'], \n",
    "                                                        train_size = i/10,\n",
    "                                                        test_size = 0.2,\n",
    "                                                        random_state=42)\n",
    "    n = len(X_train)\n",
    "    for j in range(len(X_train)):\n",
    "        words = df.loc[j,'Text'].lower()\n",
    "        words = cleaning_data(words)    \n",
    "        words = tokenize_text(words)\n",
    "\n",
    "        if df.loc[j,'Speaker'] == \"BIDEN\":\n",
    "            counter_biden += Counter(words)\n",
    "        elif df.loc[j, \"Speaker\"] == \"TRUMP\":\n",
    "            counter_trump += Counter(words)\n",
    "        elif df.loc[j, \"Speaker\"] == \"WALLACE\":\n",
    "            counter_wallace += Counter(words)\n",
    "\n",
    "    d = {\"Biden\":counter_biden,\"Trump\":counter_trump, \"Wallace\": counter_wallace}\n",
    "    wc = pd.DataFrame(d)\n",
    "    wc = wc.fillna(0)\n",
    "    wc.Biden = wc.Biden.astype(int)\n",
    "    wc.Trump = wc.Trump.astype(int)\n",
    "    wc.Wallace = wc.Wallace.astype(int)\n",
    "\n",
    "    def rev_probs(review_text, alpha = 1.0):\n",
    "\n",
    "        tot = np.array(wc.sum()).sum()\n",
    "        prod = np.ones(3)\n",
    "        prod[0] = wc['Biden'].sum()/(tot)\n",
    "        prod[1] = wc['Trump'].sum()/(tot)\n",
    "        prod[2] = wc[\"Wallace\"].sum()/(tot)\n",
    "        prod = np.log(prod)\n",
    "\n",
    "        words = cleaning_data(review_text).lower()\n",
    "        words = tokenize_text(words)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word not in stops and word in list(wc.index):\n",
    "                w = wc.loc[word]        \n",
    "                p = (w+alpha)/(np.array(wc.sum())+ 2*alpha) # The probability P[x|y] with laplace smoothing       \n",
    "                prod += np.log(np.array(p))\n",
    "\n",
    "        return prod\n",
    "\n",
    "    Y_pred = pd.DataFrame(columns = [\"Speaker\"])\n",
    "    for text in tqdm(X_test):\n",
    "        prod = rev_probs(text)\n",
    "        loc = prod.argmax()\n",
    "        if loc == 0:\n",
    "            Y_pred.loc[len(Y_pred.index)] = [\"BIDEN\"] \n",
    "        elif loc == 1:\n",
    "            Y_pred.loc[len(Y_pred.index)] = [\"TRUMP\"]\n",
    "        else:\n",
    "            Y_pred.loc[len(Y_pred.index)] = [\"WALLACE\"]\n",
    "\n",
    "    prediction = pd.DataFrame(columns = [\"Y_pred\", \"Y_test\"])\n",
    "    prediction[\"Y_pred\"] = Y_pred[\"Speaker\"]\n",
    "    prediction[\"Y_test\"] = list(y_test)\n",
    "\n",
    "    accuracy[i] = accuracy_score(prediction[\"Y_pred\"], prediction[\"Y_test\"])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 61.62790698, 70.34883721, 73.25581395, 79.06976744,\n",
       "       81.97674419, 80.81395349, 82.55813953, 84.88372093])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the accuracy of the model increases as the size of the training data increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26fc66b5a30>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(k, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets write some text samples on your own and get them classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.08825461 -0.97429526 -1.25268034]\n"
     ]
    }
   ],
   "source": [
    "review_text = \"Climate Change is a Myth.\"\n",
    "product = rev_probs(review_text, alpha = 1.0)\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for our example, Trump is most likely speaker of the above text with highest probablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.25022324 -14.65165348 -16.16558945]\n"
     ]
    }
   ],
   "source": [
    "review_text = \"America is great a nation.\"\n",
    "product = rev_probs(review_text, alpha = 1.0)\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, Biden is most likely speaker of the above text with highest probablity. Although it needs to important that both presidential candiate are likely to say that and probablities are really close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like our programme is working quite nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Naive Bayes from sklearn, Accessed April 11, 2023. https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "2. Stack Overflow. Preprocessing steps to follow while cleaning and extracting text data from tweets, Accessed April 11, 2023. https://codereview.stackexchange.com/questions/163446/preprocessing-steps-to-follow-while-cleaning-and-extracting-text-data-from-tweet.\n",
    "3. Class Notes. Accessed April 11, 2023.\n",
    "4. Pandas API Library. Accessed April 11, 2023. https://pandas.pydata.org/docs/reference/frame.html.\n",
    "5. The commission on Presenditial Debate. Accessed April 11, 2023. https://www.debates.org/voter-education/debate-transcripts/september-29-2020-debate-transcript/.\n",
    "6. Word Cloud Documention in python. Accessed April 11, 2023. https://pypi.org/project/wordcloud/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
